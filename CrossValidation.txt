
-Train/test validation:
	- train model on train set (70%)
	- evaluate the error on test set(30%):
		- allow to add hyper-parameters
-Train/Test Split procedure:
	0. Clean and adjust data as necessary for both X and y
	1. Split data in Train/Test for both X and y
	2. Fit/Train Scaler on Training X data
	3. Scale X test data
	4. Create model
	5. Fit/Train model on X Train Data
	6. Evaluate Model on X Test data (by creating predictions and comparing to Y_test)
	7. Adjust Paramteres as Necessary and repeat step 5 & 6
	
It is not a fair measure because we adjust hyper-parameters based on previous performance of Test set. So it is not 100% independenly


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = , random_state = )

#Scale data
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

#Create model
from sklearn.linear_model import Ridge

model = Ridge(alpha = 100)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

#Evaluate model
from sklearn.metrics import mean_squared_error

mean_squared_error(y_test, y_pred)














